name: Test
on: [push, pull_request]

jobs:
  tests:
    name: ${{ matrix.version }}
    runs-on: ${{ matrix.os }}
  
    strategy:
      fail-fast: false
      matrix:
        include:
          - {version: '13', os: ubuntu-latest}
          - {version: '12', os: ubuntu-latest}
          - {version: '11', os: ubuntu-latest}
          - {version: '10', os: ubuntu-latest}

    services:
      postgres:
        image: postgres:${{ matrix.version }}
        env:
          POSTGRES_PASSWORD: test
          POSTGRES_USER: test
          POSTGRES_DB: test_${{ matrix.version }}
        ports:
          - 5432:5432
        options: --health-cmd pg_isready --health-interval 5s --health-timeout 5s --health-retries 10
      s3:
        image: zenko/cloudserver
        env:
          ENDPOINT: s3
          S3BACKEND: mem
          REMOTE_MANAGEMENT_DISABLE: 1
          SCALITY_ACCESS_KEY_ID: access_key
          SCALITY_SECRET_ACCESS_KEY: secret

    steps:
      - name: Create Test Data
        uses: addnab/docker-run-action
        with:
          image: postgres:${{ matrix.version }}
          run: >
            psql -d test_${{ matrix.version }} -U test -h postgres -p ${{ job.services.postgres.ports[5432] }} -c '
              CREATE TABLE books (
                id serial PRIMARY KEY,
                name VARCHAR ( 128 ) UNIQUE NOT NULL,
                author VARCHAR (128 ) NOT NULL
              );
              INSERT INTO books (name, author) VALUES
                ($$Fittstim$$, $$Linda Skugge$$),
                ($$DSM-5$$, $$American Psychiatric Association$$);
            '
          options: >
            -e PGPASSWORD=test
      
      - name: Create S3 bucket
        uses: addnab/docker-run-action
        with:
          image: amazon/aws-cli
          run: aws --endpoint-url=http://s3:8000 s3api create-bucket --bucket test-postgresql-backup; aws --endpoint-url=http://s3:8000 s3 ls
          options: >
            -e AWS_EC2_METADATA_DISABLED=true
            -e AWS_ACCESS_KEY_ID=access_key
            -e AWS_SECRET_ACCESS_KEY=secret
      
      - uses: actions/checkout@v2

      - name: Build Docker Image
        uses: docker/build-push-action@v2
        with:
          tags: heyman/postgresql-backup:latest
          push: false
          context: ${{ matrix.version }}
      
      - name: Take Backup
        uses: addnab/docker-run-action
        with:
          image: heyman/postgresql-backup:latest
          run: python -u /backup/backup.py
          options: >
            -e S3_EXTRA_OPTIONS='--endpoint-url=http://s3:8000' 
            -e DB_HOST=postgres
            -e DB_PASS=test
            -e DB_USER=test
            -e DB_NAME=test_${{ matrix.version }}
            -e S3_PATH=s3://test-postgresql-backup/backups
            -e AWS_ACCESS_KEY_ID=access_key
            -e AWS_SECRET_ACCESS_KEY=secret
            -e AWS_DEFAULT_REGION=us-east-1
            -e FILENAME=test_${{ matrix.version }}
      
      - name: Clear DB table
        uses: addnab/docker-run-action
        with:
          image: postgres:${{ matrix.version }}
          run: >
            psql -d test_${{ matrix.version }} -U test -h postgres -p ${{ job.services.postgres.ports[5432] }} -c '
              DROP TABLE books;
            '
          options: >
            -e PGPASSWORD=test
      
      - name: Check that table was actually removed
        uses: addnab/docker-run-action
        with:
          image: postgres:${{ matrix.version }}
          shell: bash
          run: >
            [[ "0" == `psql -d test_${{ matrix.version }} -U test -h postgres -p ${{ job.services.postgres.ports[5432] }} -A -t -c '
                SELECT count(*) FROM pg_catalog.pg_tables WHERE tablename=$$books$$;
              '` ]]
          options: >
            -e PGPASSWORD=test
      
      - name: Restore Backup
        uses: addnab/docker-run-action
        with:
          image: heyman/postgresql-backup:latest
          run: python -u /backup/restore.py test_${{ matrix.version }}
          options: >
            -e S3_EXTRA_OPTIONS='--endpoint-url=http://s3:8000' 
            -e DB_HOST=postgres
            -e DB_PASS=test
            -e DB_USER=test
            -e DB_NAME=test_${{ matrix.version }}
            -e S3_PATH=s3://test-postgresql-backup/backups
            -e AWS_ACCESS_KEY_ID=access_key
            -e AWS_SECRET_ACCESS_KEY=secret
            -e AWS_DEFAULT_REGION=us-east-1
      
      - name: Check that table got imported
        uses: addnab/docker-run-action
        with:
          image: postgres:${{ matrix.version }}
          shell: bash
          run: >
            [[ "1" == `psql -d test_${{ matrix.version }} -U test -h postgres -p ${{ job.services.postgres.ports[5432] }} -A -t -c '
                SELECT count(*) FROM pg_catalog.pg_tables WHERE tablename=$$books$$;
              '` ]] && [[ "Fittstim" == `psql -d test_${{ matrix.version }} -U test -h postgres -p ${{ job.services.postgres.ports[5432] }} -A -t -c '
                SELECT name FROM books WHERE author=$$Linda Skugge$$;
              '` ]]
          options: >
            -e PGPASSWORD=test

